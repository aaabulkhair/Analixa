<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://aaabulkhair.github.io/Analixa/feed.xml" rel="self" type="application/atom+xml" /><link href="https://aaabulkhair.github.io/Analixa/" rel="alternate" type="text/html" /><updated>2022-07-01T18:30:30-05:00</updated><id>https://aaabulkhair.github.io/Analixa/feed.xml</id><title type="html">Analixa</title><subtitle>Data Science School</subtitle><entry><title type="html">So, which ML Algorithm to use?!</title><link href="https://aaabulkhair.github.io/Analixa/machine%20learning/2022/05/17/So,-Which-ML-Algorithm-to-use!.html" rel="alternate" type="text/html" title="So, which ML Algorithm to use?!" /><published>2022-05-17T00:00:00-05:00</published><updated>2022-05-17T00:00:00-05:00</updated><id>https://aaabulkhair.github.io/Analixa/machine%20learning/2022/05/17/So,%20Which%20ML%20Algorithm%20to%20use!</id><author><name></name></author><category term="Machine Learning" /><summary type="html"><![CDATA[Selecting the best ML for a dataset can always be challenging. In this post, we will try reveal a lot of the ambiguity related to that!]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://aaabulkhair.github.io/Analixa/images/which_ml_cover.gif" /><media:content medium="image" url="https://aaabulkhair.github.io/Analixa/images/which_ml_cover.gif" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Generative Adversarial Networks (GANs)</title><link href="https://aaabulkhair.github.io/Analixa/gan/deep%20learning/pytorch/python/2022/03/18/gan-generating-hand-written-digits-pytorch-1.html" rel="alternate" type="text/html" title="Generative Adversarial Networks (GANs)" /><published>2022-03-18T00:00:00-05:00</published><updated>2022-03-18T00:00:00-05:00</updated><id>https://aaabulkhair.github.io/Analixa/gan/deep%20learning/pytorch/python/2022/03/18/gan-generating-hand-written-digits-pytorch-1</id><author><name>Ahmed Abulkhair</name></author><category term="GAN" /><category term="Deep Learning" /><category term="PyTorch" /><category term="Python" /><summary type="html"><![CDATA[Generative Adversarial Networks are used to generate images that never existed before. They learn about the world (objects, animals and so forth) and create new versions of those images that never existed. In this tutorial, we will go through the basics of GANs]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://aaabulkhair.github.io/Analixa/images/GANs-1.gif" /><media:content medium="image" url="https://aaabulkhair.github.io/Analixa/images/GANs-1.gif" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">GPT-3, The Model Simply Knows!</title><link href="https://aaabulkhair.github.io/Analixa/gpt-3/nlp/research%20paper/2022/03/08/GPT-3,-The-Model-Simply-Knows.html" rel="alternate" type="text/html" title="GPT-3, The Model Simply Knows!" /><published>2022-03-08T00:00:00-06:00</published><updated>2022-03-08T00:00:00-06:00</updated><id>https://aaabulkhair.github.io/Analixa/gpt-3/nlp/research%20paper/2022/03/08/GPT-3,%20The%20Model%20Simply%20Knows</id><author><name></name></author><category term="GPT-3" /><category term="NLP" /><category term="Research Paper" /><summary type="html"><![CDATA[GPT-3 is one of the greatest leaps in the area of NLP. In this post, we will try to go through the basics of the algorithm and how it is working.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://aaabulkhair.github.io/Analixa/images/GPT-3-preview.gif" /><media:content medium="image" url="https://aaabulkhair.github.io/Analixa/images/GPT-3-preview.gif" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Text Preprocessing | NLP 1</title><link href="https://aaabulkhair.github.io/Analixa/machine%20learning/nlp/nltk/2022/02/07/nlp-text-preprocessing-1.html" rel="alternate" type="text/html" title="Text Preprocessing | NLP 1" /><published>2022-02-07T00:00:00-06:00</published><updated>2022-02-07T00:00:00-06:00</updated><id>https://aaabulkhair.github.io/Analixa/machine%20learning/nlp/nltk/2022/02/07/nlp-text-preprocessing-1</id><author><name>Ahmed Abulkhair</name></author><category term="Machine Learning" /><category term="NLP" /><category term="NLTK" /><summary type="html"><![CDATA[In this tutorial, I tried to demonstrate the basic concepts of `preprocessing` for natural text starting from `stopwords removal`, `lowering`, and `lemmetization`.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://aaabulkhair.github.io/Analixa/images/nlp1.png" /><media:content medium="image" url="https://aaabulkhair.github.io/Analixa/images/nlp1.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Titanic | The Power of Sklearn</title><link href="https://aaabulkhair.github.io/Analixa/machine%20learning/sklearn/python/2022/02/05/titanic-power-of-scikit-learn.html" rel="alternate" type="text/html" title="Titanic | The Power of Sklearn" /><published>2022-02-05T00:00:00-06:00</published><updated>2022-02-05T00:00:00-06:00</updated><id>https://aaabulkhair.github.io/Analixa/machine%20learning/sklearn/python/2022/02/05/titanic-power-of-scikit-learn</id><author><name>Ahmed Abulkhair</name></author><category term="Machine Learning" /><category term="Sklearn" /><category term="Python" /><summary type="html"><![CDATA[Sklearn is the most powerful package in all ML libraries but, do you really use it to the fullest?! In this notebook, we will try to investigate deep concepts such as ColumnTransformers, Piplines, and much more.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://aaabulkhair.github.io/Analixa/images/titanic.png" /><media:content medium="image" url="https://aaabulkhair.github.io/Analixa/images/titanic.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>